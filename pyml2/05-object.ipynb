{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7c851b",
   "metadata": {},
   "source": [
    "# Python и машинное обучение: нейронные сети и компьютерное зрение\n",
    "\n",
    "## Модуль 5. Распознавание объектов на изображениях\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1bea4b",
   "metadata": {},
   "source": [
    "### YOLOv5\n",
    "\n",
    "По состоянию на декабрь 2023 года - \"базовая\" и самая простая модель для поиска объектов на фотографиях. Загружаем на ```torch.hub```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \\\n",
    "    \"mps\" if torch.backends.mps.is_built() else \"cpu\"\n",
    "device\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c9ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaae4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ultralytics.com/images/zidane.jpg -q -O input.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('input.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b48779",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model('input.jpg')\n",
    "\n",
    "df = results.pandas().xyxy[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print()\n",
    "results.xyxy[0]  # img1 predictions (tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl = round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n",
    "tl=2\n",
    "tf = max(tl - 1, 1)\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    xA, yA, xB, yB = map(int, row[:4])\n",
    "    cv2.rectangle(img, (xA, yA), (xB, yB), (0, 255, 0), tl)\n",
    "    cv2.putText(img, row['name'], (xA, yA - 2), 0, tl / 3, [0, 255, 0], thickness=tf, lineType=cv2.LINE_AA) \n",
    "    \n",
    "display(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1faeca",
   "metadata": {},
   "source": [
    "## Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58820ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48781321",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "im = cv2.imread(\"./input.jpg\")\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be260140",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = outputs['instances'].pred_masks.cpu().numpy().astype('uint8')[0]\n",
    "contour, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "image_with_overlaid_predictions = im.copy()\n",
    "cv2.drawContours(image_with_overlaid_predictions, [contour[0]], -1, (0,255,0), 1)\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(image_with_overlaid_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd97c1",
   "metadata": {},
   "source": [
    "## Дообучение модели YOLO\n",
    "\n",
    "\n",
    "\n",
    "### **Форматы аннотаций**\n",
    "Аннотации описывают координаты объектов на изображении и их классы.\n",
    "\n",
    "#### a) **COCO (Common Objects in Context)**  \n",
    "- **Формат**: JSON  \n",
    "- Описание: Аннотации включают координаты объектов в формате прямоугольников (bounding boxes), а также информацию о сегментации (масках).\n",
    "- Пример:\n",
    "```json\n",
    "{\n",
    "  \"images\": [{\"id\": 1, \"file_name\": \"image1.jpg\"}],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"image_id\": 1,\n",
    "      \"bbox\": [x, y, width, height],\n",
    "      \"category_id\": 1,\n",
    "      \"segmentation\": [[...]]\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [{\"id\": 1, \"name\": \"cat\"}]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### b) **Pascal VOC**  \n",
    "- **Формат**: XML  \n",
    "- Описание: Каждый объект на изображении представлен прямоугольником (bounding box) с координатами и классом.  \n",
    "- Пример:\n",
    "```xml\n",
    "<annotation>\n",
    "  <folder>images</folder>\n",
    "  <filename>image1.jpg</filename>\n",
    "  <object>\n",
    "    <name>cat</name>\n",
    "    <bndbox>\n",
    "      <xmin>50</xmin>\n",
    "      <ymin>50</ymin>\n",
    "      <xmax>150</xmax>\n",
    "      <ymax>150</ymax>\n",
    "    </bndbox>\n",
    "  </object>\n",
    "</annotation>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### c) **YOLO (You Only Look Once)**  \n",
    "- **Формат**: TXT  \n",
    "- Описание: Каждый объект записывается в виде строки: `<class> <x_center> <y_center> <width> <height>`. Координаты нормализуются в диапазон от 0 до 1.  \n",
    "- Пример:  \n",
    "```txt\n",
    "0 0.5 0.5 0.25 0.25\n",
    "```\n",
    "\n",
    "https://colab.research.google.com/drive/1Plz91PHWwf04bYt21mnWp7qBcDIvJ6J6\n",
    "\n",
    "https://medium.com/mlearning-ai/training-yolov5-custom-dataset-with-ease-e4f6272148ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install\n",
    "\n",
    "import torch\n",
    "from yolov5 import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78803ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /content/drive/MyDrive/mask_archive.zip ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os, sys\n",
    "\n",
    "zip_file = \"mask_archive.zip\"\n",
    "\n",
    "if os.path.isfile(zip_file):\n",
    "    shutil.unpack_archive(zip_file, \"data\")\n",
    "else:\n",
    "    print(zip_file + \" not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d24463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "\n",
    "# preparing the folder structure\n",
    "\n",
    "full_data_path = 'data/obj/'\n",
    "extension_allowed = '.jpg'\n",
    "split_percentage = 90\n",
    "\n",
    "images_path = 'data/images/'\n",
    "if os.path.exists(images_path):\n",
    "    shutil.rmtree(images_path)\n",
    "os.mkdir(images_path)\n",
    "\n",
    "labels_path = 'data/labels/'\n",
    "if os.path.exists(labels_path):\n",
    "    shutil.rmtree(labels_path)\n",
    "os.mkdir(labels_path)\n",
    "\n",
    "training_images_path = images_path + 'training/'\n",
    "validation_images_path = images_path + 'validation/'\n",
    "training_labels_path = labels_path + 'training/'\n",
    "validation_labels_path = labels_path +'validation/'\n",
    "\n",
    "os.mkdir(training_images_path)\n",
    "os.mkdir(validation_images_path)\n",
    "os.mkdir(training_labels_path)\n",
    "os.mkdir(validation_labels_path)\n",
    "\n",
    "files = []\n",
    "\n",
    "ext_len = len(extension_allowed)\n",
    "\n",
    "for r, d, f in os.walk(full_data_path):\n",
    "    for file in f:\n",
    "        if file.endswith(extension_allowed):\n",
    "            strip = file[0:len(file) - ext_len]\n",
    "            files.append(strip)\n",
    "\n",
    "random.shuffle(files)\n",
    "\n",
    "size = len(files)\n",
    "\n",
    "split = int(split_percentage * size / 100)\n",
    "\n",
    "print(\"copying training data\")\n",
    "for i in range(split):\n",
    "    strip = files[i]\n",
    "\n",
    "    image_file = strip + extension_allowed\n",
    "    src_image = full_data_path + image_file\n",
    "    shutil.copy(src_image, training_images_path)\n",
    "\n",
    "    annotation_file = strip + '.txt'\n",
    "    src_label = full_data_path + annotation_file\n",
    "    shutil.copy(src_label, training_labels_path)\n",
    "\n",
    "print(\"copying validation data\")\n",
    "for i in range(split, size):\n",
    "    strip = files[i]\n",
    "\n",
    "    image_file = strip + extension_allowed\n",
    "    src_image = full_data_path + image_file\n",
    "    shutil.copy(src_image, validation_images_path)\n",
    "\n",
    "    annotation_file = strip + '.txt'\n",
    "    src_label = full_data_path + annotation_file\n",
    "    shutil.copy(src_label, validation_labels_path)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset.yaml\", \"a\")\n",
    "\n",
    "f.write(\"train: ../data/images/training/\\n\")\n",
    "f.write(\"val: ../data/images/validation/\\n\")\n",
    "f.write(\"nc: 2\\n\")\n",
    "f.write(\"names: ['with mask', 'without mask']\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea466bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "!python train.py --img 640 --batch 16 --epochs 5 --data ../dataset.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335edbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.4 --source ../test.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f53a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import PIL\n",
    "\n",
    "image_path = \"runs/detect/exp2/test.jpg\"\n",
    "# display(PIL.Image.open(image_path))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = plt.imread(image_path)\n",
    "plt.imshow(im)\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
